# Unreasonable-Effectiveness-of-Machine-Learning

Final project report for CS264 (Beyond Worst-Case Analysis) at Stanford in 2017. While the worst-case analysis of algorithms has undeniably produced tremendous success in advancing our theoretical understanding of computation, this approach does harbor several drawbacks. For instance, worst-case analysis might provide an overly pessimistic outloook since real-world inputs may not be adversarially generated. In addition, worst-case analysis often leaves a gap between theory and practice where the theory fails to explain why certain algorithms succeed over others empirically. A classic example of this gap is in linear programming where the Simplex Method typically performs blazingly fast in practice, but runs in exponential time on certain inputs. This course explored several ideas for analyzing algorithms that seek to go beyond the standard worst-case analysis.

In our final project report, we focused on machine learning, a field with numerous glaring examples of this wedge between theory and practice. In many cases, worst-case analyze labels many machine learning problems as hopeless as the tasks are often NP-Hard, non-convex, or otherwise intractable. Nevertheless, simple heuristics often perform brilliantly in practice and there is no denying the transformative effect that machine learning has had (and will almost certainly continue to have) on the world. In this project, we surveyed several recent research papers that provide theoretical justificiations for the unreasonable effectiveness of machine learning. In particular, we focused our attention on three thematic areas: (1) the stability of stochastic gradient descent, (2) alternating minimization for matrix completion and dictionary learning, and (3) provable guarantees for topic modeling.    
